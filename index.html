<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Kafka 101: Schema Registry</title>

		<meta name="description" content="An introductory presentation on the Kafka's RESTful interface for storing and retrieving schemas">
		<meta name="author" content="Frank Wisniewski, Lars Pfannenschmidt">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/night.css" id="theme">
		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">
		<!-- Custom stylesheet -->
		<link rel="stylesheet" href="css/custom.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section data-background="img/front-page-blur.png" id="front-page">
					<h3>Kafka 101</h3>
					<h1>Schema Registry</h1>
					<p>
						<small><a href="https://github.com/frankwis">Frank</a> / <a href="http://twitter.com/ultraknackig">@ultraknackig</a></small>
						<small>&amp; <a href="https://github.com/larsp">Lars</a> / <a href="http://twitter.com/leastangle">@leastangle</a></small>
					</p>
				</section>

				<section data-background="img/front-page-blur.png" id="content">
					<h2>What to expect</h2>
					<ul>
						<li>Serialization</li>
						<li>Apache Avro&trade;</li>
						<li>Schema Registry</li>
						<ul>
							<li>REST API</li>
							<li>Producer</li>
							<li>Consumer</li>
						</ul>
					</ul>
				</section>

				<section id="motivation" data-background="#FFB03B">
					<section>
						<h1>Serialization</h1>
					</section>
					<section>
						<h2>The Evolution of Serialization</h2>
						<ol>
							<li>Built-in Serialization</li>
							<li>JSON/XML</li>
							<li>Binary</li>
							<li>Schema</li>
						</ol>
						<aside class="notes">
							<ul>
								<li>Programming languageâ€™s native frameworks.</li>
								<li>Language-agnostic, not locked into particular PL.</li>
								<li>Reduces verbosity, increases parsing performance, differentiates between int and longs</li>
								<li>Separation of Schema and Data Persistence
									<ul>
										<li>cross-language</li>
										<li>no more data with inconsistent type; generate model for static typed PLs</li>
										<li>save even more space by omitting field names</li>
									</ul>
								</li>
							</ul>
						 </aside>
					</section>

					<section>
						<h2>Eventually, the schema changes</h2>
						<aside class="notes">
							<ul>
								<li>code refactoring or DB schema changes</li>
								<li>results in both ugly and unmaintainable code</li>
								<li>developers who are tired of having to modify their scripts again and again.</li>
								<li>schema changes happen frequently, and often without warning.</li>
							</ul>
						 </aside>
					</section>

					<section>
						<h2>Schema Evolution</h2>
						<ul>
							<li>Backward compatibility</li>
							<li>Forward compatibility</li>
							<li>Full compatibility</li>
						</ul>
						<aside class="notes">
							<ul>
								<li>new schema can be used to read the data written in all previous schemas</li>
								<li>all previous schemas can read data written in this schema</li>
								<li>backward and forward compatible</li>
							</ul>
						 </aside>
					</section>
				</section>

				<section id="avro" data-background="#B64926">
					<section>
						<h1>Avro</h1>
					</section>
					<section>
						<h2>Structuring Data in Kafka</h2>
						<pre><code data-trim>
curl -X POST -i -H "Content-Type: application/vnd.schemaregistry.v1+json" \
  --data '{"schema":"{\"type\":\"fixed\", \"name\":\"IPv4\", \"size\":4}"}' \
  http://127.0.0.1:8081/subjects/ip/versions
            </code></pre>
						<pre><code data-trim>
{
  "type":"fixed",
  "name":"IPv4",
  "size":4
}
						</code></pre>
						<aside class="notes">
							<ul>
								<li>size: an integer, specifying the number of bytes per value (required).</li>
								<li>IPv4 uses 32-bit (four-byte) addresses</li>
							</ul>
						 </aside>
					</section>

					<section>
						<h2>Schema Declaration</h2>
						<h4>Primitive Types</h4>
						null, boolean, int, long, float, double, bytes, string
						<pre><code data-trim>
"string"
{"type": "int"}
            </code></pre>
						<span class="fragment">
						  <h4>Complex Types</h4>
						  records, enums, arrays, maps, unions, fixed
						  <pre><code data-trim>
{
  "type":"record",
  "name":"Click",
  "namespace":"io.kafka101.clickstream.schema.domain",
  "fields":[
    {
      "name":"time",
      "type":"string"
    },
    {
      "name":"page",
      "type":"string"
    },
  ...
  ]
}
  					  </code></pre>
						  </p>
						  <aside class="notes">
							  <ul>
								  <li>schemas may be maintained manually or generated out of the domain model</li>
								  <li>API for handling schemas</li>
									<li>Jackson like annotations</li>
							  </ul>
						  </aside>
					</section>

					<section>
						<h2>Schema Evolution</h2>
						Evlolving a schema using a <code data-trim>UNION</code>
<pre><code data-trim>
[
  {
    "type":"fixed",
    "name":"IPv4",
    "size":4
  },
  {
    "type":"fixed",
    "name":"IPv6",
    "size":16
  }
]
</code></pre>
					</section>
					<section>
						<h2>Conflict Resolution</h2>
<pre><code data-trim>
@AvroDefault("\"unknown\"")
public final String user;

@Nullable
public final String origin;

@AvroIgnore
private boolean processed = false;

public Click(String time, String ip, String page, String user, String origin) {
    super(time, ip, page);
    this.user = user;
    this.origin = origin;
}
</code></pre>
						<aside class="notes">
							<ul>
								<li>@AvroEncode for CustomEncoding implementations</li>
								<li>@AvroAlias old names maybe attached as an alias</li>
								<li>Jackson like annotations</li>
							</ul>
						</aside>
					</section>
				</section>

				<section id="schema-registry" data-background="#8E2800">
					<section>
						<h1>Schema Registry</h1>
					</section>
					<section>
						<h2>Overview</h2>
						<img width="50%" src="img/schema-registry.svg">
					</section>

					<section id="schema-api">
						<h2>REST API</h2>
						<pre class="fragment"><code data-trim>
curl -X POST -i -H "Content-Type: application/vnd.schemaregistry.v1+json" \
	--data '{"schema":"{\"type\":\"fixed\", \"name\":\"IPv4\", \"size\":4}"}' \
	http://127.0.0.1:8081/subjects/ip/versions
						</code></pre>
						<pre class="fragment"><code data-trim>
curl -i -H "Content-Type: application/vnd.schemaregistry.v1+json" \
	http://127.0.0.1:8081/subjects/ip/versions/1
						</code></pre>
						<pre class="fragment"><code data-trim>
curl -X POST -i -H "Content-Type: application/vnd.schemaregistry.v1+json" \
	--data '{"schema":"[ {\"type\":\"fixed\", \"name\":\"IPv4\", \"size\":4}, {\"type\":\"fixed\", \"name\":\"IPv6\", \"size\":16}]"}' \
	http://127.0.0.1:8081/subjects/ip/versions
						</code></pre>
						<a class="fragment" href="http://docs.confluent.io/1.0/schema-registry/docs/api.html">API Reference</a>
					</section>

					<section id="producer">
						<h2>Producer</h2>
						<pre class="fragment"><code class="java" data-trim>
public class Producer {

...

    public Producer(String topic, String broker, String registryUrl) throws JsonMappingException {
        this.topic = topic;
        this.producer = createProducer(broker, registryUrl);
        this.translator = new AvroTranslator();
    }

    private KafkaProducer&lt;String, GenericRecord&gt; createProducer(String broker, String registryUrl) {
        Properties config = new Properties();
        config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, broker);
        config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class.getName());
        config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class.getName());
        config.put(AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, registryUrl);
        return new KafkaProducer&lt;&gt;(config);
    }
...
}
						</code></pre>
					</section>

					<section>
						<h2>send()</h2>
						<pre><code class="java" data-trim>
public class Producer {

...

	public RecordMetadata send(Click click) throws ExecutionException, InterruptedException {
        GenericRecord genericRecord = translator.toAvro(click);
        ProducerRecord&lt;String, GenericRecord&gt; record = new ProducerRecord&lt;&gt;(topic, click.ip, genericRecord);
        return this.producer.send(record).get();
    }
...
}
						</code></pre>
					</section>

					<section>
						<h2>AvroTranslator.java?</h2>
					</section>

					<section id="consumer">
						<h2>Consumer</h2>
						<pre class="fragment"><code class="java" data-trim>
public class Consumer&lt;T&gt; {

...
    private Properties getConfiguration(String zookeeper, String schemaUrl, String groupId) {
    	...
        props.put("schema.registry.url", schemaUrl);
        return props;
    }
...
    public void run(int numThreads) {
        Map&lt;String, Integer&gt; topicCountMap = new HashMap();
        topicCountMap.put(topic, new Integer(numThreads));
        KafkaAvroDecoder avroDecoder = new KafkaAvroDecoder(new VerifiableProperties(configuration));
        Map&lt;String, List&lt;KafkaStream&lt;Object, Object&gt;&gt;&gt; consumerMap = consumerConnector.createMessageStreams(
                topicCountMap, avroDecoder, avroDecoder);
        List&lt;KafkaStream&lt;Object, Object&gt;&gt; streams = consumerMap.get(topic);

        // create fixed size thread pool to launch all the threads
        pool = Executors.newFixedThreadPool(numThreads);
        // create consumer threads to handle the messages
        int threadNumber = 0;

        for (final KafkaStream stream : streams) {
            String name = String.format("%s[%s]", consumer.getTopic(), threadNumber++);
            Runnable runnable = new ConsumerThread(stream, name, consumer);
            pool.submit(runnable);
        }
    }
}
						</code></pre>
					</section>
					<section>
						<h2>ConsumerThread</h2>
						<pre><code class="java" data-trim>
public class ConsumerThread implements Runnable {
...
    @Override
    public void run() {
        Thread.currentThread().setName(name);
        logger.info("Started consumer thread {}", name);
        ConsumerIterator&lt;String, Object&gt; it = messageStream.iterator();
        while (it.hasNext()) {
            relayMessage(it.next());
        }
        logger.info("Shutting down consumer thread {}", name);
    }

    private void relayMessage(MessageAndMetadata&lt;String, Object&gt; kafkaMessage) {
        logger.debug("Received message with key '{}' and offset '{}' on partition '{}' for topic '{}'",
                kafkaMessage.key(), kafkaMessage.offset(), kafkaMessage.partition(), kafkaMessage.topic());
        GenericContainer record = (GenericContainer) kafkaMessage.message();
        Click click = translator.toObject(record, Click.class);
        consumer.consume(click);
    }
}
						</code></pre>
					</section>
					<section>
						Sample Code: <a href="https://github.com/kafka101/clickstream-schema">github.com/kafka101/clickstream-schema</a><br>
						Chef &amp; Vagrantfile: <a href="https://supermarket.chef.io/cookbooks/confluent-cookbook">supermarket.chef.io/cookbooks/confluent-cookbook</a><br>
						Kafka intro: <a href="https://github.com/kafka101/java-news-feed">github.com/kafka101/java-news-feed</a><br>
					</section>
					</section>

				<section id="end">
					<h2>Questions?</h2>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,
				width: 1280,
        		height: 800,
        		margin: 0.1,
        		minScale: 1,
        		maxScale: 1.2,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
